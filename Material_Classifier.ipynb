{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.__version__ is 2.2.0\n",
      "tf.keras.__version__ is: 2.3.0-tf\n",
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TF_KERAS'] = '1'\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "import onnx\n",
    "import keras\n",
    "import onnx2keras\n",
    "from onnx2keras import onnx_to_keras\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "import keras2onnx\n",
    "\n",
    "from tensorflow.python.keras.models import load_model\n",
    "from tensorflow.python.client import device_lib\n",
    "#print(device_lib.list_local_devices())\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imread\n",
    "\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image\n",
    "from torchvision.transforms import functional\n",
    "from PIL import Image\n",
    "\n",
    "print(\"tf.__version__ is\", tf.__version__)\n",
    "print(\"tf.keras.__version__ is:\", tf.keras.__version__)\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "\n",
    "\n",
    "PIL_transform = transforms.ToPILImage()\n",
    "tensor_transform = transforms.ToTensor()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_model.get_layer(index=0).kernel_regularizer = regularizers.l2(0.0001)\n",
    "k_model.get_layer(index=0).bias_regularizer = regularizers.l2(0.0001)\n",
    "\n",
    "k_model.get_layer(index=1).kernel_regularizer = regularizers.l2(0.0001)\n",
    "k_model.get_layer(index=1).bias_regularizer = regularizers.l2(0.0001)\n",
    "\n",
    "k_model.get_layer(index=2).kernel_regularizer = regularizers.l2(0.0001)\n",
    "k_model.get_layer(index=2).bias_regularizer = regularizers.l2(0.0001)\n",
    "\n",
    "k_model.get_layer(index=3).kernel_regularizer = regularizers.l2(0.0001)\n",
    "k_model.get_layer(index=3).bias_regularizer = regularizers.l2(0.0001)\n",
    "\n",
    "k_model.get_layer(index=4).kernel_regularizer = regularizers.l2(0.0001)\n",
    "k_model.get_layer(index=4).bias_regularizer = regularizers.l2(0.0001)\n",
    "\n",
    "k_model.get_layer(index=5).kernel_regularizer = regularizers.l2(0.0001)\n",
    "k_model.get_layer(index=5).bias_regularizer = regularizers.l2(0.0001)\n",
    "\n",
    "k_model.get_layer(index=6).kernel_regularizer = regularizers.l2(0.0001)\n",
    "k_model.get_layer(index=6).bias_regularizer = regularizers.l2(0.0001)\n",
    "\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for features, label in training_data:\n",
    "    X.append(features)\n",
    "    y.append(label)\n",
    "    \n",
    "X = np.array(X).reshape(-1,1,IMG_SIZE,IMG_SIZE, 1)\n",
    "y = np.array(y)\n",
    "\n",
    "pickle_out = open(\"X.pickle\", \"wb\")\n",
    "pickle.dump(X,pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_out = open(\"y.pickle\", \"wb\")\n",
    "pickle.dump(y,pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pickle.load(open(\"X.pickle\",\"rb\"))\n",
    "y = pickle.load(open(\"y.pickle\",\"rb\"))\n",
    "\n",
    "#X = X/255.0\n",
    "VAL_PCT = 0.1  # lets reserve 10% of our data for validation\n",
    "val_size = int(len(X)*VAL_PCT)\n",
    "\n",
    "train_X = X[:-val_size]\n",
    "train_y = y[:-val_size]\n",
    "\n",
    "test_X = X[-val_size:]\n",
    "test_y = y[-val_size:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "4569/4569 [==============================] - 14s 3ms/step - loss: 0.0548 - accuracy: 0.9315\n",
      "Epoch 2/100\n",
      "4569/4569 [==============================] - 13s 3ms/step - loss: 0.0232 - accuracy: 0.9709\n",
      "Epoch 3/100\n",
      "4569/4569 [==============================] - 13s 3ms/step - loss: 0.0147 - accuracy: 0.9812\n",
      "Epoch 4/100\n",
      "4569/4569 [==============================] - 13s 3ms/step - loss: 0.0107 - accuracy: 0.9873\n",
      "Epoch 5/100\n",
      "4569/4569 [==============================] - 14s 3ms/step - loss: 0.0084 - accuracy: 0.9895\n",
      "Epoch 6/100\n",
      "4569/4569 [==============================] - 13s 3ms/step - loss: 0.0064 - accuracy: 0.9926\n",
      "Epoch 7/100\n",
      "4569/4569 [==============================] - 14s 3ms/step - loss: 0.0078 - accuracy: 0.9917\n",
      "Epoch 8/100\n",
      "4569/4569 [==============================] - 14s 3ms/step - loss: 0.0065 - accuracy: 0.9919\n",
      "Epoch 9/100\n",
      "4569/4569 [==============================] - 14s 3ms/step - loss: 0.0052 - accuracy: 0.9932\n",
      "Epoch 10/100\n",
      "4569/4569 [==============================] - 14s 3ms/step - loss: 0.0015 - accuracy: 0.9980\n",
      "Epoch 11/100\n",
      "4569/4569 [==============================] - 14s 3ms/step - loss: 0.0069 - accuracy: 0.9923\n",
      "Epoch 12/100\n",
      "4569/4569 [==============================] - 14s 3ms/step - loss: 0.0040 - accuracy: 0.9950\n",
      "Epoch 13/100\n",
      "4569/4569 [==============================] - 14s 3ms/step - loss: 2.2105e-04 - accuracy: 0.9998\n",
      "Epoch 14/100\n",
      "4569/4569 [==============================] - 14s 3ms/step - loss: 0.0036 - accuracy: 0.9956\n",
      "Epoch 15/100\n",
      "4569/4569 [==============================] - 13s 3ms/step - loss: 0.0033 - accuracy: 0.9961\n",
      "Epoch 16/100\n",
      "4569/4569 [==============================] - 14s 3ms/step - loss: 0.0015 - accuracy: 0.9976\n",
      "Epoch 17/100\n",
      "4569/4569 [==============================] - 14s 3ms/step - loss: 0.0035 - accuracy: 0.9961\n",
      "Epoch 18/100\n",
      "4569/4569 [==============================] - 14s 3ms/step - loss: 4.4185e-04 - accuracy: 0.9996\n",
      "Epoch 19/100\n",
      "4569/4569 [==============================] - 14s 3ms/step - loss: 1.7790e-07 - accuracy: 1.0000\n",
      "Epoch 20/100\n",
      "4569/4569 [==============================] - 14s 3ms/step - loss: 8.6337e-09 - accuracy: 1.0000\n",
      "Epoch 21/100\n",
      "4569/4569 [==============================] - 14s 3ms/step - loss: 2.5692e-09 - accuracy: 1.0000\n",
      "Epoch 22/100\n",
      "4569/4569 [==============================] - 14s 3ms/step - loss: 4.8269e-10 - accuracy: 1.0000\n",
      "Epoch 23/100\n",
      "4569/4569 [==============================] - 14s 3ms/step - loss: 4.8465e-11 - accuracy: 1.0000\n",
      "Epoch 24/100\n",
      "4569/4569 [==============================] - 14s 3ms/step - loss: 1.1608e-11 - accuracy: 1.0000\n",
      "Epoch 25/100\n",
      "4569/4569 [==============================] - 14s 3ms/step - loss: 4.7476e-12 - accuracy: 1.0000\n",
      "Epoch 26/100\n",
      "4569/4569 [==============================] - 14s 3ms/step - loss: 3.0275e-12 - accuracy: 1.0000\n",
      "Epoch 27/100\n",
      "4569/4569 [==============================] - 14s 3ms/step - loss: 2.1477e-12 - accuracy: 1.0000\n",
      "Epoch 28/100\n",
      "4569/4569 [==============================] - 14s 3ms/step - loss: 1.6963e-12 - accuracy: 1.0000\n",
      "Epoch 29/100\n",
      "4569/4569 [==============================] - 14s 3ms/step - loss: 1.4134e-12 - accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "4569/4569 [==============================] - 14s 3ms/step - loss: 1.2102e-12 - accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "4569/4569 [==============================] - 14s 3ms/step - loss: 1.0616e-12 - accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "4569/4569 [==============================] - 14s 3ms/step - loss: 9.4744e-13 - accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "4569/4569 [==============================] - 14s 3ms/step - loss: 8.5702e-13 - accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "4569/4569 [==============================] - 14s 3ms/step - loss: 7.8194e-13 - accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "4569/4569 [==============================] - 13s 3ms/step - loss: 7.1680e-13 - accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "4569/4569 [==============================] - 14s 3ms/step - loss: 6.6399e-13 - accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "4569/4569 [==============================] - 14s 3ms/step - loss: 6.1792e-13 - accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "4569/4569 [==============================] - 15s 3ms/step - loss: 5.7733e-13 - accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "4569/4569 [==============================] - 15s 3ms/step - loss: 5.4121e-13 - accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "4569/4569 [==============================] - 14s 3ms/step - loss: 5.0987e-13 - accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "4569/4569 [==============================] - 14s 3ms/step - loss: 4.8278e-13 - accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "4569/4569 [==============================] - 14s 3ms/step - loss: 4.5797e-13 - accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "4569/4569 [==============================] - 14s 3ms/step - loss: 4.3416e-13 - accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "4569/4569 [==============================] - 14s 3ms/step - loss: 4.1605e-13 - accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "4569/4569 [==============================] - 14s 3ms/step - loss: 3.9657e-13 - accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "4569/4569 [==============================] - 14s 3ms/step - loss: 3.8019e-13 - accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "4569/4569 [==============================] - 14s 3ms/step - loss: 3.6492e-13 - accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "4569/4569 [==============================] - 14s 3ms/step - loss: 3.5103e-13 - accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "4569/4569 [==============================] - 14s 3ms/step - loss: 3.3769e-13 - accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "4569/4569 [==============================] - 14s 3ms/step - loss: 3.2495e-13 - accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "4569/4569 [==============================] - 14s 3ms/step - loss: 3.1365e-13 - accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "4569/4569 [==============================] - 14s 3ms/step - loss: 3.0235e-13 - accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "4569/4569 [==============================] - 14s 3ms/step - loss: 2.9285e-13 - accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "4569/4569 [==============================] - 14s 3ms/step - loss: 2.8354e-13 - accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "4569/4569 [==============================] - 14s 3ms/step - loss: 2.7465e-13 - accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "4569/4569 [==============================] - 14s 3ms/step - loss: 2.6647e-13 - accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "4569/4569 [==============================] - 15s 3ms/step - loss: 2.5905e-13 - accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "4569/4569 [==============================] - 14s 3ms/step - loss: 2.5130e-13 - accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "4569/4569 [==============================] - 14s 3ms/step - loss: 2.4518e-13 - accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "4569/4569 [==============================] - 14s 3ms/step - loss: 2.3823e-13 - accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "4569/4569 [==============================] - 14s 3ms/step - loss: 2.3248e-13 - accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "4569/4569 [==============================] - 14s 3ms/step - loss: 2.2664e-13 - accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "4569/4569 [==============================] - 14s 3ms/step - loss: 2.2171e-13 - accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "4569/4569 [==============================] - 14s 3ms/step - loss: 2.1608e-13 - accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "4569/4569 [==============================] - 14s 3ms/step - loss: 2.1103e-13 - accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "4569/4569 [==============================] - 14s 3ms/step - loss: 2.0592e-13 - accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "4569/4569 [==============================] - 14s 3ms/step - loss: 2.0111e-13 - accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "4569/4569 [==============================] - 14s 3ms/step - loss: 1.9700e-13 - accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "4569/4569 [==============================] - 14s 3ms/step - loss: 1.9279e-13 - accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "4569/4569 [==============================] - 14s 3ms/step - loss: 1.8874e-13 - accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "4569/4569 [==============================] - 14s 3ms/step - loss: 1.8541e-13 - accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "4569/4569 [==============================] - 14s 3ms/step - loss: 1.8089e-13 - accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "4569/4569 [==============================] - 15s 3ms/step - loss: 1.7765e-13 - accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "4569/4569 [==============================] - 15s 3ms/step - loss: 1.7414e-13 - accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "4569/4569 [==============================] - 14s 3ms/step - loss: 1.7081e-13 - accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "4569/4569 [==============================] - 14s 3ms/step - loss: 1.6815e-13 - accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "4569/4569 [==============================] - 14s 3ms/step - loss: 1.6516e-13 - accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "4569/4569 [==============================] - 14s 3ms/step - loss: 1.6197e-13 - accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "4569/4569 [==============================] - 14s 3ms/step - loss: 1.5904e-13 - accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "4569/4569 [==============================] - 14s 3ms/step - loss: 1.5661e-13 - accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "4569/4569 [==============================] - 15s 3ms/step - loss: 1.5363e-13 - accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "4569/4569 [==============================] - 14s 3ms/step - loss: 1.5131e-13 - accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "4569/4569 [==============================] - 14s 3ms/step - loss: 1.4872e-13 - accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "4569/4569 [==============================] - 14s 3ms/step - loss: 1.4626e-13 - accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "4569/4569 [==============================] - 14s 3ms/step - loss: 1.4424e-13 - accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "4569/4569 [==============================] - 14s 3ms/step - loss: 1.4168e-13 - accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "4569/4569 [==============================] - 14s 3ms/step - loss: 1.3983e-13 - accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "4569/4569 [==============================] - 14s 3ms/step - loss: 1.3802e-13 - accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "4569/4569 [==============================] - 14s 3ms/step - loss: 1.3548e-13 - accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "4569/4569 [==============================] - 14s 3ms/step - loss: 1.3372e-13 - accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "4569/4569 [==============================] - 14s 3ms/step - loss: 1.3183e-13 - accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "4569/4569 [==============================] - 14s 3ms/step - loss: 1.2969e-13 - accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "4569/4569 [==============================] - 15s 3ms/step - loss: 1.2783e-13 - accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "4569/4569 [==============================] - 15s 3ms/step - loss: 1.2631e-13 - accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "4569/4569 [==============================] - 14s 3ms/step - loss: 1.2459e-13 - accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "4569/4569 [==============================] - 14s 3ms/step - loss: 1.2313e-13 - accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "4569/4569 [==============================] - 14s 3ms/step - loss: 1.2132e-13 - accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "4569/4569 [==============================] - 14s 3ms/step - loss: 1.1983e-13 - accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "4569/4569 [==============================] - 14s 3ms/step - loss: 1.1818e-13 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "4569/4569 [==============================] - 14s 3ms/step - loss: 1.1678e-13 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x291c1f02cf8>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_model.compile(loss=\"mean_squared_error\", optimizer=\"adam\",metrics=['accuracy'])\n",
    "k_model.fit(train_X,train_y, batch_size=1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "507/507 [==============================] - 1s 2ms/step - loss: 0.0187 - accuracy: 0.9803\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.01865518093109131, 0.9802761077880859]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_model.evaluate(test_X, test_y, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:onnx2keras:Converter is called.\n",
      "DEBUG:onnx2keras:List input shapes:\n",
      "DEBUG:onnx2keras:None\n",
      "DEBUG:onnx2keras:List inputs:\n",
      "DEBUG:onnx2keras:Input 0 -> imageinput_Mean.\n",
      "DEBUG:onnx2keras:Input 1 -> conv_1_W.\n",
      "DEBUG:onnx2keras:Input 2 -> conv_1_B.\n",
      "DEBUG:onnx2keras:Input 3 -> batchnorm_1_scale.\n",
      "DEBUG:onnx2keras:Input 4 -> batchnorm_1_B.\n",
      "DEBUG:onnx2keras:Input 5 -> batchnorm_1_mean.\n",
      "DEBUG:onnx2keras:Input 6 -> batchnorm_1_var.\n",
      "DEBUG:onnx2keras:Input 7 -> conv_2_W.\n",
      "DEBUG:onnx2keras:Input 8 -> conv_2_B.\n",
      "DEBUG:onnx2keras:Input 9 -> batchnorm_2_scale.\n",
      "DEBUG:onnx2keras:Input 10 -> batchnorm_2_B.\n",
      "DEBUG:onnx2keras:Input 11 -> batchnorm_2_mean.\n",
      "DEBUG:onnx2keras:Input 12 -> batchnorm_2_var.\n",
      "DEBUG:onnx2keras:Input 13 -> conv_3_W.\n",
      "DEBUG:onnx2keras:Input 14 -> conv_3_B.\n",
      "DEBUG:onnx2keras:Input 15 -> batchnorm_3_scale.\n",
      "DEBUG:onnx2keras:Input 16 -> batchnorm_3_B.\n",
      "DEBUG:onnx2keras:Input 17 -> batchnorm_3_mean.\n",
      "DEBUG:onnx2keras:Input 18 -> batchnorm_3_var.\n",
      "DEBUG:onnx2keras:Input 19 -> conv_4_W.\n",
      "DEBUG:onnx2keras:Input 20 -> conv_4_B.\n",
      "DEBUG:onnx2keras:Input 21 -> batchnorm_4_scale.\n",
      "DEBUG:onnx2keras:Input 22 -> batchnorm_4_B.\n",
      "DEBUG:onnx2keras:Input 23 -> batchnorm_4_mean.\n",
      "DEBUG:onnx2keras:Input 24 -> batchnorm_4_var.\n",
      "DEBUG:onnx2keras:Input 25 -> conv_5_W.\n",
      "DEBUG:onnx2keras:Input 26 -> conv_5_B.\n",
      "DEBUG:onnx2keras:Input 27 -> batchnorm_5_scale.\n",
      "DEBUG:onnx2keras:Input 28 -> batchnorm_5_B.\n",
      "DEBUG:onnx2keras:Input 29 -> batchnorm_5_mean.\n",
      "DEBUG:onnx2keras:Input 30 -> batchnorm_5_var.\n",
      "DEBUG:onnx2keras:Input 31 -> fc_1_W.\n",
      "DEBUG:onnx2keras:Input 32 -> fc_1_B.\n",
      "DEBUG:onnx2keras:Input 33 -> fc_2_W.\n",
      "DEBUG:onnx2keras:Input 34 -> fc_2_B.\n",
      "DEBUG:onnx2keras:Input 35 -> imageinput.\n",
      "DEBUG:onnx2keras:List outputs:\n",
      "DEBUG:onnx2keras:Output 0 -> softmax.\n",
      "DEBUG:onnx2keras:Gathering weights to dictionary.\n",
      "DEBUG:onnx2keras:Found weight imageinput_Mean with shape (1, 1, 1, 1).\n",
      "DEBUG:onnx2keras:Found weight conv_1_W with shape (2, 1, 3, 3).\n",
      "DEBUG:onnx2keras:Found weight conv_1_B with shape (2,).\n",
      "DEBUG:onnx2keras:Found weight batchnorm_1_scale with shape (2,).\n",
      "DEBUG:onnx2keras:Found weight batchnorm_1_B with shape (2,).\n",
      "DEBUG:onnx2keras:Found weight batchnorm_1_mean with shape (2,).\n",
      "DEBUG:onnx2keras:Found weight batchnorm_1_var with shape (2,).\n",
      "DEBUG:onnx2keras:Found weight conv_2_W with shape (4, 2, 3, 3).\n",
      "DEBUG:onnx2keras:Found weight conv_2_B with shape (4,).\n",
      "DEBUG:onnx2keras:Found weight batchnorm_2_scale with shape (4,).\n",
      "DEBUG:onnx2keras:Found weight batchnorm_2_B with shape (4,).\n",
      "DEBUG:onnx2keras:Found weight batchnorm_2_mean with shape (4,).\n",
      "DEBUG:onnx2keras:Found weight batchnorm_2_var with shape (4,).\n",
      "DEBUG:onnx2keras:Found weight conv_3_W with shape (8, 4, 3, 3).\n",
      "DEBUG:onnx2keras:Found weight conv_3_B with shape (8,).\n",
      "DEBUG:onnx2keras:Found weight batchnorm_3_scale with shape (8,).\n",
      "DEBUG:onnx2keras:Found weight batchnorm_3_B with shape (8,).\n",
      "DEBUG:onnx2keras:Found weight batchnorm_3_mean with shape (8,).\n",
      "DEBUG:onnx2keras:Found weight batchnorm_3_var with shape (8,).\n",
      "DEBUG:onnx2keras:Found weight conv_4_W with shape (16, 8, 3, 3).\n",
      "DEBUG:onnx2keras:Found weight conv_4_B with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight batchnorm_4_scale with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight batchnorm_4_B with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight batchnorm_4_mean with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight batchnorm_4_var with shape (16,).\n",
      "DEBUG:onnx2keras:Found weight conv_5_W with shape (32, 16, 3, 3).\n",
      "DEBUG:onnx2keras:Found weight conv_5_B with shape (32,).\n",
      "DEBUG:onnx2keras:Found weight batchnorm_5_scale with shape (32,).\n",
      "DEBUG:onnx2keras:Found weight batchnorm_5_B with shape (32,).\n",
      "DEBUG:onnx2keras:Found weight batchnorm_5_mean with shape (32,).\n",
      "DEBUG:onnx2keras:Found weight batchnorm_5_var with shape (32,).\n",
      "DEBUG:onnx2keras:Found weight fc_1_W with shape (128, 32, 12, 12).\n",
      "DEBUG:onnx2keras:Found weight fc_1_B with shape (128,).\n",
      "DEBUG:onnx2keras:Found weight fc_2_W with shape (2, 128, 1, 1).\n",
      "DEBUG:onnx2keras:Found weight fc_2_B with shape (2,).\n",
      "DEBUG:onnx2keras:Found input imageinput with shape [1, 200, 200]\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Sub\n",
      "DEBUG:onnx2keras:node_name: imageinput_Sub\n",
      "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name imageinput).\n",
      "DEBUG:onnx2keras:Check input 1 (name imageinput_Mean).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:sub:Convert inputs to Keras/TF layers if needed.\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"imageinput_Sub_9/Identity:0\", shape=(None, 1, 200, 200), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Conv\n",
      "DEBUG:onnx2keras:node_name: conv_1\n",
      "DEBUG:onnx2keras:node_params: {'group': 1, 'dilations': [1, 1], 'kernel_shape': [3, 3], 'pads': [1, 1, 1, 1], 'strides': [1, 1], 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name imageinput_Sub).\n",
      "DEBUG:onnx2keras:Check input 1 (name conv_1_W).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 2 (name conv_1_B).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:conv:Conv with bias\n",
      "DEBUG:onnx2keras:conv:2D convolution\n",
      "DEBUG:onnx2keras:conv:Paddings exist, add ZeroPadding layer\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"conv_1_9/Identity:0\", shape=(None, 2, 200, 200), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: BatchNormalization\n",
      "DEBUG:onnx2keras:node_name: batchnorm_1\n",
      "DEBUG:onnx2keras:node_params: {'epsilon': 9.999999747378752e-06, 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name conv_1).\n",
      "DEBUG:onnx2keras:Check input 1 (name batchnorm_1_scale).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 2 (name batchnorm_1_B).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 3 (name batchnorm_1_mean).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 4 (name batchnorm_1_var).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"batchnorm_1_9/Identity:0\", shape=(None, 2, 200, 200), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Relu\n",
      "DEBUG:onnx2keras:node_name: relu_1\n",
      "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name batchnorm_1).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"relu_1_9/Identity:0\", shape=(None, 2, 200, 200), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: MaxPool\n",
      "DEBUG:onnx2keras:node_name: maxpool_1\n",
      "DEBUG:onnx2keras:node_params: {'kernel_shape': [2, 2], 'pads': [0, 0, 0, 0], 'strides': [2, 2], 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name relu_1).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "WARNING:onnx2keras:maxpool:Unable to use `same` padding. Add ZeroPadding2D layer to fix shapes.\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"maxpool_1_9/Identity:0\", shape=(None, 2, 100, 100), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Conv\n",
      "DEBUG:onnx2keras:node_name: conv_2\n",
      "DEBUG:onnx2keras:node_params: {'group': 1, 'dilations': [1, 1], 'kernel_shape': [3, 3], 'pads': [1, 1, 1, 1], 'strides': [1, 1], 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name maxpool_1).\n",
      "DEBUG:onnx2keras:Check input 1 (name conv_2_W).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 2 (name conv_2_B).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:conv:Conv with bias\n",
      "DEBUG:onnx2keras:conv:2D convolution\n",
      "DEBUG:onnx2keras:conv:Paddings exist, add ZeroPadding layer\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"conv_2_9/Identity:0\", shape=(None, 4, 100, 100), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: BatchNormalization\n",
      "DEBUG:onnx2keras:node_name: batchnorm_2\n",
      "DEBUG:onnx2keras:node_params: {'epsilon': 9.999999747378752e-06, 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name conv_2).\n",
      "DEBUG:onnx2keras:Check input 1 (name batchnorm_2_scale).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 2 (name batchnorm_2_B).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 3 (name batchnorm_2_mean).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 4 (name batchnorm_2_var).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"batchnorm_2_9/Identity:0\", shape=(None, 4, 100, 100), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Relu\n",
      "DEBUG:onnx2keras:node_name: relu_2\n",
      "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name batchnorm_2).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"relu_2_9/Identity:0\", shape=(None, 4, 100, 100), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: MaxPool\n",
      "DEBUG:onnx2keras:node_name: maxpool_2\n",
      "DEBUG:onnx2keras:node_params: {'kernel_shape': [2, 2], 'pads': [0, 0, 0, 0], 'strides': [2, 2], 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name relu_2).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "WARNING:onnx2keras:maxpool:Unable to use `same` padding. Add ZeroPadding2D layer to fix shapes.\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"maxpool_2_9/Identity:0\", shape=(None, 4, 50, 50), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Conv\n",
      "DEBUG:onnx2keras:node_name: conv_3\n",
      "DEBUG:onnx2keras:node_params: {'group': 1, 'dilations': [1, 1], 'kernel_shape': [3, 3], 'pads': [1, 1, 1, 1], 'strides': [1, 1], 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name maxpool_2).\n",
      "DEBUG:onnx2keras:Check input 1 (name conv_3_W).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 2 (name conv_3_B).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:conv:Conv with bias\n",
      "DEBUG:onnx2keras:conv:2D convolution\n",
      "DEBUG:onnx2keras:conv:Paddings exist, add ZeroPadding layer\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"conv_3_9/Identity:0\", shape=(None, 8, 50, 50), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: BatchNormalization\n",
      "DEBUG:onnx2keras:node_name: batchnorm_3\n",
      "DEBUG:onnx2keras:node_params: {'epsilon': 9.999999747378752e-06, 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name conv_3).\n",
      "DEBUG:onnx2keras:Check input 1 (name batchnorm_3_scale).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 2 (name batchnorm_3_B).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 3 (name batchnorm_3_mean).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 4 (name batchnorm_3_var).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"batchnorm_3_9/Identity:0\", shape=(None, 8, 50, 50), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Relu\n",
      "DEBUG:onnx2keras:node_name: relu_3\n",
      "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name batchnorm_3).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"relu_3_9/Identity:0\", shape=(None, 8, 50, 50), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: MaxPool\n",
      "DEBUG:onnx2keras:node_name: maxpool_3\n",
      "DEBUG:onnx2keras:node_params: {'kernel_shape': [2, 2], 'pads': [0, 0, 0, 0], 'strides': [2, 2], 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name relu_3).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "WARNING:onnx2keras:maxpool:Unable to use `same` padding. Add ZeroPadding2D layer to fix shapes.\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"maxpool_3_9/Identity:0\", shape=(None, 8, 25, 25), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Conv\n",
      "DEBUG:onnx2keras:node_name: conv_4\n",
      "DEBUG:onnx2keras:node_params: {'group': 1, 'dilations': [1, 1], 'kernel_shape': [3, 3], 'pads': [1, 1, 1, 1], 'strides': [1, 1], 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name maxpool_3).\n",
      "DEBUG:onnx2keras:Check input 1 (name conv_4_W).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 2 (name conv_4_B).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:conv:Conv with bias\n",
      "DEBUG:onnx2keras:conv:2D convolution\n",
      "DEBUG:onnx2keras:conv:Paddings exist, add ZeroPadding layer\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"conv_4_9/Identity:0\", shape=(None, 16, 25, 25), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: BatchNormalization\n",
      "DEBUG:onnx2keras:node_name: batchnorm_4\n",
      "DEBUG:onnx2keras:node_params: {'epsilon': 9.999999747378752e-06, 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name conv_4).\n",
      "DEBUG:onnx2keras:Check input 1 (name batchnorm_4_scale).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 2 (name batchnorm_4_B).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 3 (name batchnorm_4_mean).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 4 (name batchnorm_4_var).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"batchnorm_4_9/Identity:0\", shape=(None, 16, 25, 25), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Relu\n",
      "DEBUG:onnx2keras:node_name: relu_4\n",
      "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name batchnorm_4).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"relu_4_9/Identity:0\", shape=(None, 16, 25, 25), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: MaxPool\n",
      "DEBUG:onnx2keras:node_name: maxpool_4\n",
      "DEBUG:onnx2keras:node_params: {'kernel_shape': [2, 2], 'pads': [0, 0, 0, 0], 'strides': [2, 2], 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name relu_4).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "WARNING:onnx2keras:maxpool:Unable to use `same` padding. Add ZeroPadding2D layer to fix shapes.\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"maxpool_4_9/Identity:0\", shape=(None, 16, 12, 12), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Conv\n",
      "DEBUG:onnx2keras:node_name: conv_5\n",
      "DEBUG:onnx2keras:node_params: {'group': 1, 'dilations': [1, 1], 'kernel_shape': [3, 3], 'pads': [1, 1, 1, 1], 'strides': [1, 1], 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name maxpool_4).\n",
      "DEBUG:onnx2keras:Check input 1 (name conv_5_W).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 2 (name conv_5_B).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:conv:Conv with bias\n",
      "DEBUG:onnx2keras:conv:2D convolution\n",
      "DEBUG:onnx2keras:conv:Paddings exist, add ZeroPadding layer\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"conv_5_9/Identity:0\", shape=(None, 32, 12, 12), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: BatchNormalization\n",
      "DEBUG:onnx2keras:node_name: batchnorm_5\n",
      "DEBUG:onnx2keras:node_params: {'epsilon': 9.999999747378752e-06, 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name conv_5).\n",
      "DEBUG:onnx2keras:Check input 1 (name batchnorm_5_scale).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 2 (name batchnorm_5_B).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 3 (name batchnorm_5_mean).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 4 (name batchnorm_5_var).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"batchnorm_5_9/Identity:0\", shape=(None, 32, 12, 12), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Relu\n",
      "DEBUG:onnx2keras:node_name: relu_5\n",
      "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name batchnorm_5).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"relu_5_9/Identity:0\", shape=(None, 32, 12, 12), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Conv\n",
      "DEBUG:onnx2keras:node_name: fc_1\n",
      "DEBUG:onnx2keras:node_params: {'group': 1, 'dilations': [1, 1], 'kernel_shape': [12, 12], 'pads': [0, 0, 0, 0], 'strides': [1, 1], 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name relu_5).\n",
      "DEBUG:onnx2keras:Check input 1 (name fc_1_W).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 2 (name fc_1_B).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:conv:Conv with bias\n",
      "DEBUG:onnx2keras:conv:2D convolution\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"fc_1_9/Identity:0\", shape=(None, 128, 1, 1), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Relu\n",
      "DEBUG:onnx2keras:node_name: relu_6\n",
      "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name fc_1).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"relu_6_9/Identity:0\", shape=(None, 128, 1, 1), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Conv\n",
      "DEBUG:onnx2keras:node_name: fc_2\n",
      "DEBUG:onnx2keras:node_params: {'group': 1, 'dilations': [1, 1], 'kernel_shape': [1, 1], 'pads': [0, 0, 0, 0], 'strides': [1, 1], 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name relu_6).\n",
      "DEBUG:onnx2keras:Check input 1 (name fc_2_W).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 2 (name fc_2_B).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:conv:Conv with bias\n",
      "DEBUG:onnx2keras:conv:2D convolution\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"fc_2_9/Identity:0\", shape=(None, 2, 1, 1), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Flatten\n",
      "DEBUG:onnx2keras:node_name: softmax_Flatten\n",
      "DEBUG:onnx2keras:node_params: {'axis': 1, 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name fc_2).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:flatten:Convert inputs to Keras/TF layers if needed.\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"softmax_Flatten_9/Identity:0\", shape=(None, None), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Softmax\n",
      "DEBUG:onnx2keras:node_name: softmax\n",
      "DEBUG:onnx2keras:node_params: {'axis': 1, 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name softmax_Flatten).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"softmax_9/Identity:0\", shape=(None, None), dtype=float32)\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 2571/2571 [00:01<00:00, 1397.98it/s]\n",
      "  5%|████▏                                                                        | 135/2506 [00:00<00:01, 1340.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "carbon: 2570\n",
      "fiberglass: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 2506/2506 [00:01<00:00, 1396.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "carbon: 2570\n",
      "fiberglass: 2506\n",
      "training data length: 5076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "onnx_model = onnx.load(\"Material_Classifier.onnx\")\n",
    "k_model = onnx_to_keras(onnx_model, ['imageinput'])\n",
    "\n",
    "keras.models.save_model(k_model, \"Material_Classifier.h5\", overwrite=True,include_optimizer=True)\n",
    "\n",
    "\n",
    "IMG_SIZE=200\n",
    "CARBON = \"CARBON/\"\n",
    "FIBERGLASS = \"FIBERGLASS/\"\n",
    "LABELS = {CARBON: 0, FIBERGLASS: 1}\n",
    "training_data = []\n",
    "\n",
    "carbon_count = 0\n",
    "fiberglass_count = 0\n",
    "\n",
    "\n",
    "for label in LABELS:\n",
    "    for f in tqdm(os.listdir(label)):\n",
    "        if \"jpg\" in f:\n",
    "            try:\n",
    "                path = os.path.join(label,f)\n",
    "                img = cv2.imread(path,cv2.IMREAD_GRAYSCALE)\n",
    "                img = cv2.resize(img, (IMG_SIZE,IMG_SIZE))\n",
    "                \n",
    "                #---------------------------------------------\n",
    "                '''\n",
    "                plt.imshow(img, cmap = \"gray\")\n",
    "                plt.show()\n",
    "                '''\n",
    "                #---------------------------------------------\n",
    "                \n",
    "                \n",
    "                # randomize numbers ----------------------------------------------------------------------------------\n",
    "                #degrees = abs(random.uniform(0.0,10.0)) # Get the degree range\n",
    "                #scale = random.uniform(.5,2.0) # Get the scale range\n",
    "                #horizontal_translation_factor = random.uniform(0.0,.2) # Get the translation factor range\n",
    "                #vertical_translation_factor = random.uniform(0.0,.2)\n",
    "                # randomize numbers ----------------------------------------------------------------------------------            \n",
    "                # transform assuming that it does the operation implicitly and needs no variable assigning\n",
    "                #PIL_image = PIL_transform(img)\n",
    "                #PIL_image = transforms.functional.affine(PIL_image,degrees,(horizontal_translation_factor, vertical_translation_factor),scale,shear = 0, resample=0,fillcolor=None)\n",
    "                # if label == self.NEGATIVE:\n",
    "                    # save = PIL_image.save(\"Transforms/Bad/\" + f)\n",
    "\n",
    "                # elif label == self.POSITIVE:\n",
    "                    # save = PIL_image.save(\"Transforms/Good/\" + f)\n",
    "                \n",
    "                #tensor_transform(PIL_image)\n",
    "\n",
    "                training_data.append([np.array(img), np.eye(2)[LABELS[label]]])\n",
    "\n",
    "\n",
    "\n",
    "                if label == CARBON:\n",
    "\n",
    "                    carbon_count =carbon_count + 1\n",
    "                elif label == FIBERGLASS:\n",
    "\n",
    "                    fiberglass_count = fiberglass_count + 1\n",
    "            except Exception as e:\n",
    "                print(\"bad things\")\n",
    "                pass\n",
    "\n",
    "    np.random.shuffle(training_data)\n",
    "    print('carbon:', carbon_count)\n",
    "    print('fiberglass:', fiberglass_count)\n",
    "\n",
    "#training_data = np.load(\"training_data.npy\", allow_pickle=True)\n",
    "print(\"training data length:\", len(training_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
